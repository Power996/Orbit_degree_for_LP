{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import shap\n",
    "from tqdm import tqdm\n",
    "import os.path\n",
    "from scipy import linalg\n",
    "import scipy.sparse as sparse\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from xgboost import XGBClassifier  \n",
    "from sklearn.model_selection import StratifiedKFold \n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.model_selection import train_test_split \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance(X,y,Is_sort_feature=0):\n",
    "    '''输入：\n",
    "        参数1：样本的特征数据\n",
    "        参数2：样本标签\n",
    "        参数3：是否对特征进行重要性得分计算，只有融合多特征时才需要\n",
    "        \n",
    "        输出，特征得分、auc值、precision值、recall值、f-score值\n",
    "    '''\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42, stratify=y) #按照y的标签平衡样本\n",
    "    xgbc=XGBClassifier(**best_params)\n",
    "    \n",
    "    #训练模型\n",
    "    xgbc.fit(X_train, y_train)\n",
    "    \n",
    "    #prediction on test set\n",
    "    dtree_predictions = xgbc.predict(X_test) #离散的0或者1\n",
    "    dtree_proba = xgbc.predict_proba(X_test) #预测为0和1的概率二元组[0.22396779 0.7760322],前为0概率,后为1概率\n",
    "    \n",
    "    #评估\n",
    "    auc_measure = roc_auc_score(y_test, dtree_proba[:, 1])#AUC计算，是以概率计算\n",
    "    precision_total, recall_total, f_measure_total, _ = precision_recall_fscore_support(y_test, dtree_predictions,\n",
    "                                                                                        average=None)\n",
    "    \n",
    "    if Is_sort_feature == 1:\n",
    "        explainer = shap.TreeExplainer(xgbc)\n",
    "        shap_values = explainer.shap_values(X_test)\n",
    "        importances = np.mean(np.abs(shap_values), axis=0) #每个特征的重要性,根据shap_values计算得出\n",
    "        feature_importances = importances\n",
    "    else:\n",
    "        feature_importances = None\n",
    "    return feature_importances,auc_measure,precision_total[1], recall_total[1], f_measure_total[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is the program that calculates the performance and SHAP VALUES of one time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global best_params \n",
    "best_params = {'eval_metric':'auc'}\n",
    "node_features = ['N1', 'N2', 'N3', 'N4', 'N5', 'N6', 'N7', 'N8', 'N9', 'N10', 'N11', 'N12', 'N13', 'N14', 'N15']\n",
    "edge_features = ['M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9', 'M10', 'M11', 'M12']\n",
    "A = defaultdict(list) #stow performance\n",
    "Features_importance_score =  defaultdict(list)#stow shap values\n",
    "n = 550 #number of networks\n",
    "for i in tqdm(range(n)):\n",
    "    data = pd.read_csv(f'./features/n_{i}_features.csv')\n",
    "    features = data.columns.tolist()[2:]\n",
    "    \n",
    "    #single feature\n",
    "    for f in features:\n",
    "        X = data[f].values\n",
    "        X = X.reshape(-1, 1)\n",
    "        y = data['label']\n",
    "        _, auc,precision, recall, f_score = performance(X,y)\n",
    "        A[f'n_{i}_auc'].append(auc)\n",
    "        A[f'n_{i}_precision'].append(precision)\n",
    "        A[f'n_{i}_recall'].append(recall)\n",
    "        A[f'n_{i}_f-score'].append(f_score)\n",
    "        \n",
    "    #multi-feature fusing\n",
    "    XX = data[node_features].values\n",
    "    yy = data['label']\n",
    "    _,auc,precision, recall, f_score = performance(XX,yy,Is_sort_feature=0)\n",
    "    A[f'n_{i}_auc'].append(auc)\n",
    "    A[f'n_{i}_precision'].append(precision)\n",
    "    A[f'n_{i}_recall'].append(recall)\n",
    "    A[f'n_{i}_f-score'].append(f_score)\n",
    "    \n",
    "    XX = data[edge_features].values\n",
    "    yy = data['label']\n",
    "    _,auc,precision, recall, f_score = performance(XX,yy,Is_sort_feature=0)\n",
    "    A[f'n_{i}_auc'].append(auc)\n",
    "    A[f'n_{i}_precision'].append(precision)\n",
    "    A[f'n_{i}_recall'].append(recall)\n",
    "    A[f'n_{i}_f-score'].append(f_score)\n",
    "    \n",
    "        \n",
    "    XX = data[node_features+edge_features].values\n",
    "    yy = data['label']\n",
    "    feature_importances,auc,precision, recall, f_score = performance(XX,yy,Is_sort_feature=1)\n",
    "    A[f'n_{i}_auc'].append(auc)\n",
    "    A[f'n_{i}_precision'].append(precision)\n",
    "    A[f'n_{i}_recall'].append(recall)\n",
    "    A[f'n_{i}_f-score'].append(f_score)\n",
    "    \n",
    "    \n",
    "    feature_importances1 = []\n",
    "    for j in range(len(feature_importances)):\n",
    "        feature_importances1.append((features[j],feature_importances[j]))\n",
    "            \n",
    "    #feature importance score\n",
    "    sort_feature_importances = sorted(feature_importances1, key=lambda x: x[1],reverse=True)#按照得分排序\n",
    "    Features_importance_score[f'n_{i}']  = sort_feature_importances    \n",
    "    \n",
    "    \n",
    "df1 = pd.DataFrame(A) #\n",
    "auc_col = [f'n_{x}_auc' for x in range(n)]\n",
    "precision_col = [f'n_{x}_precision' for x in range(n)]\n",
    "recall_col = [f'n_{x}_recall' for x in range(n)]\n",
    "fscore_col = [f'n_{x}_f-score' for x in range(n)]\n",
    "\n",
    "#mean\n",
    "df1['auc_avg'] = df1[auc_col].mean(axis=1) \n",
    "df1['precision_avg'] = df1[precision_col].mean(axis=1) \n",
    "df1['recall_avg'] = df1[recall_col].mean(axis=1) \n",
    "df1['f-score_avg'] = df1[fscore_col].mean(axis=1)\n",
    "\n",
    "#\n",
    "df1['auc_std'] = df1[auc_col].std(axis=1) \n",
    "df1['precision_std'] = df1[precision_col].std(axis=1) \n",
    "df1['recall_std'] = df1[recall_col].std(axis=1) \n",
    "df1['f-score_std'] = df1[fscore_col].std(axis=1)\n",
    "df1.index = features + ['ND','ED','ALL']\n",
    "\n",
    "\n",
    "df2 = pd.DataFrame(Features_importance_score)#\n",
    "df2.index = node_features+edge_features \n",
    "# df2['average'] = df2.iloc[:,0:].mean(axis=1) #\n",
    "# df2['std'] = df2.iloc[:,0:].std(axis=1) #\n",
    "    \n",
    "    \n",
    "df1.to_csv(f'./results/performance1.csv')#\n",
    "df2.to_csv(f'./results/shap_values1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add domain information to the results of shap_values\n",
    "import pickle \n",
    "infile = open('OLP_updated.pickle','rb')  \n",
    "df = pickle.load(infile)\n",
    "infile.close()  \n",
    "\n",
    "# read edge lists for all networks\n",
    "df_edgelists = df['edges_id']                               \n",
    "all_name = list(df['network_name'])\n",
    "domain_list = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    edges_orig = df_edgelists.iloc[i] # a numpy array of edge list for original graph\n",
    "    file = df['network_name'][i]\n",
    "    num_edges = df['number_edges'][i] #\n",
    "    num_nodes = df['number_nodes'][i]\n",
    "    ave_degree = df['ave_degree'][i]\n",
    "    domain = df['networkDomain'][i]\n",
    "    sub_domain = df['subDomain'][i]\n",
    "    domain_list.append(domain+'/'+sub_domain)\n",
    "    \n",
    "shap_values =  pd.read_csv('./results/shap_values1.csv',index_col = 0)\n",
    "shap_values.loc['domain'] = domain_list\n",
    "indexss = ['Top'+str(i) for i in range(1,28)]\n",
    "indexss.append('domain')\n",
    "shap_values.index = indexss\n",
    "shap_values .to_csv(f'./results/shap_values1_domain.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
